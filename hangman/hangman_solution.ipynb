{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the Hangman Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lessons from the Baseline\n",
    "\n",
    "The baseline `guess` function seems reasonable enough but achieves only about 18% accuracy, probably because it overlooks the fact that the test dictionary is completely different from the training one. It tries to always match input words _globally_ to the training dictionary, but the calculated letter frequencies will fail to reflect that of the input word as more matches are made, since no exact matches exist. \n",
    "\n",
    "This can be corroborated by using input words from the training set itself. My test shows that in this case the baseline `guess` will achieve ~90% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Algorithm Based on Matching N-grams\n",
    "\n",
    "Therefore, we will instead look for matching opportunities in local contexts. These are common letter combinations such as  _pro-_, _dis-_, _-tion_, and _-ing_. Word roots are good examples, but we'll just use n-grams to more generally represent these local contexts that are assumed to be equally common in the testing dictionary as in the training one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm:\n",
    "\n",
    "1. The n-gram probabilities (`ngram_ps`) are first calculated base on the training file during initialization. The default is to build probabilities for 2-, 3-, and 4-grams.\n",
    "\n",
    "```\n",
    "             0         1             2             3\n",
    "h  3.778638e-07  0.000002  3.297863e-01  7.732188e-07\n",
    "g  4.751117e-02  0.000002  1.453896e-01  3.240721e-02\n",
    "d  4.524873e-03  0.000002  8.865222e-02  1.851840e-02\n",
    "l  2.262437e-03  0.000002  3.900698e-02  1.111104e-01\n",
    "u  2.262437e-03  0.000002  5.922546e-07  4.629601e-03\n",
    "p  8.687757e-01  0.881169  1.028366e-01  7.732188e-07\n",
    "v  3.778638e-07  0.000002  2.127653e-01  3.888865e-01\n",
    "k  3.778638e-07  0.000002  3.546089e-03  7.732188e-07\n",
    "w  2.262437e-02  0.000002  3.546089e-03  7.732188e-07\n",
    "f  2.488680e-02  0.009901  1.418436e-02  8.333282e-02\n",
    "b  2.714924e-02  0.108909  5.673742e-02  3.564793e-01\n",
    "x  3.778638e-07  0.000002  3.546089e-03  7.732188e-07\n",
    "y  3.778638e-07  0.000002  5.922546e-07  7.732188e-07\n",
    "j  3.778638e-07  0.000002  5.922546e-07  7.732188e-07\n",
    "z  3.778638e-07  0.000002  5.922546e-07  4.629601e-03\n",
    "q  3.778638e-07  0.000002  5.922546e-07  7.732188e-07\n",
    "```\n",
    "\n",
    "2. During the guess, we maintain a probability matrix `p` (a pandas `Dataframe`) like the one shown above, whose rows are the letters and columns the positions in the input word. `p[a,j]` is the probability that letter `a` will be at position `j`. \n",
    "\n",
    "    - `p` will be initialized with the overall single letter probabilities (1-gram).\n",
    "\n",
    "    - Look for a blank in the input word next to a run of k revealed positions. Together they corespond to a list of (k+1)-grams by allowing the blank to variate. Use the n-gram probabilities to update the corresponding columns of `p`. Word beginning and endings will be represented by `<` and `>` and also matched.\n",
    "\n",
    "    - Any used letters and revealed positions are removed from the rows and columns of `p`. `p` is always normalized (all columns sum to 1).\n",
    "\n",
    "3. When there are no more match opportunities, each remaining letter `a` in `p` will be assigned an overall probability of it appearing somewhere in the word.\n",
    "\n",
    "```\n",
    "p[a] = 1 - (1 - p[a, 0]) * (1 - p[a, 1]) * (1 - p[a, 2]) * ...\n",
    "```\n",
    "4. Finally, a letter is randomly selected, weighted by its overall probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import collections\n",
    "\n",
    "from urllib.parse import parse_qs, urlencode, urlparse\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HangmanTest(object):\n",
    "    def __init__(self, access_token=None, session=None, timeout=None,\n",
    "                max_ngram=5, # maximum 5-grams\n",
    "                training_file=\"words_250000_train.txt\"):\n",
    "        \n",
    "        with open(training_file) as file:\n",
    "            self.full_dictionary = file.read().splitlines()\n",
    "        self.current_dictionary = []\n",
    "        \n",
    "        self.hangman_url = self.determine_hangman_url()\n",
    "        self.access_token = access_token\n",
    "        self.session = session or requests.Session()\n",
    "        self.timeout = timeout\n",
    "\n",
    "        self.guessed_letters = set()\n",
    "\n",
    "        self.max_ngram = max_ngram\n",
    "        self.ngram_ps = dict()\n",
    "\n",
    "        # init the n-gram probabilities \n",
    "        counts = collections.Counter(\"\".join(self.full_dictionary)) # single letter\n",
    "        self.ngram_ps[1] = pd.Series(counts) / counts.total()\n",
    "\n",
    "        for n in range(2, self.max_ngram+1): # n-gram (n > 1)\n",
    "            counts = collections.Counter(\n",
    "                [f\"<{w}>\"[i:i+n] for w in self.full_dictionary for i in range(len(w) - n + 3)])\n",
    "            self.ngram_ps[n] = pd.Series(counts) / counts.total()\n",
    "        \n",
    "        \n",
    "    def gen_contextual_ps(self, dotted: str):\n",
    "        \"\"\" generate the n-gram matching probabilities \"\"\"\n",
    "        if \".\" not in dotted:\n",
    "            return\n",
    "        \n",
    "        chunks = dotted.split(\".\") # split to runs of known letters\n",
    "        dot_index = -1   # index of the dot in input\n",
    "        pattern = \"\"\n",
    "        for j in range(len(chunks) - 1):\n",
    "            combined = chunks[j] + \".\" + chunks[j+1]\n",
    "            lj = len(chunks[j])\n",
    "            dot_index = dotted.index(\".\", dot_index+1)\n",
    "\n",
    "            if combined == \".\": # no context around\n",
    "                continue\n",
    "\n",
    "            if len(combined) <= self.max_ngram:\n",
    "                pattern = combined\n",
    "            elif lj < self.max_ngram:\n",
    "                pattern = combined[:self.max_ngram]\n",
    "            else:\n",
    "                pattern = combined[lj+1-self.max_ngram : lj+1]\n",
    "\n",
    "            ps = self.ngram_ps[len(pattern)]\n",
    "            i = pattern.index(\".\") # dot index in pattern\n",
    "            ps = ps[ps.index.str.match(pattern.replace(\".\", \"[a-z]\"))].rename(\n",
    "                index=lambda a: a[i]\n",
    "            )\n",
    "            yield dot_index-1, ps\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def determine_hangman_url():\n",
    "        links = ['https://trexsim.com', 'https://sg.trexsim.com']\n",
    "\n",
    "        data = {link: 0 for link in links}\n",
    "\n",
    "        for link in links:\n",
    "\n",
    "            requests.get(link)\n",
    "\n",
    "            for i in range(10):\n",
    "                s = time.time()\n",
    "                requests.get(link)\n",
    "                data[link] = time.time() - s\n",
    "\n",
    "        link = sorted(data.items(), key=lambda x: x[1])[0][0]\n",
    "        link += '/trexsim/hangman'\n",
    "        return link\n",
    "\n",
    "    def guess(self, masked: str) -> str: # word input example: \"_ p p _ e \"\n",
    "        # remove spaces, add start/end markers, and substitute . for _\n",
    "        dotted = f\"<{masked}>\".translate(str.maketrans({\"_\": \".\", \" \": None}))\n",
    "        \n",
    "        p = pd.DataFrame(\n",
    "            # default probabilities are those of single letters (1-gram)\n",
    "            data={j: self.ngram_ps[1] for j in range(len(dotted)-2)},\n",
    "            dtype=float)\n",
    "        \n",
    "        for column, ps in self.gen_contextual_ps(dotted):\n",
    "            p.loc[:, column] = ps\n",
    "        p.fillna(1e-10, inplace=True)\n",
    "\n",
    "        # remove guessed letters (rows)\n",
    "        p.drop(\n",
    "            index=list(self.guessed_letters.intersection(p.index)),\n",
    "            inplace=True)\n",
    "        p = p.div(p.sum()) # normalize by column\n",
    "        p.fillna(0., inplace=True)\n",
    "\n",
    "        # remove revealed positions (columns)\n",
    "        p.drop(\n",
    "            columns=[j-1 for j, a in enumerate(dotted) if a.isalpha()], \n",
    "            inplace=True)\n",
    "\n",
    "        # print(\"p = \", p, sep=\"\\n\")\n",
    "                \n",
    "        # guess the letter based on overall probability\n",
    "        candidates = (1-(1-p).prod(axis=\"columns\")).nlargest()\n",
    "        guessed_letter = np.random.choice(\n",
    "            a=candidates.index,\n",
    "            p=candidates.values/candidates.sum())\n",
    "\n",
    "        return guessed_letter\n",
    "\n",
    "\n",
    "    ##########################################################\n",
    "    # You'll likely not need to modify any of the code below #\n",
    "    ##########################################################\n",
    "    \n",
    "    def build_dictionary(self, dictionary_file_location):\n",
    "        text_file = open(dictionary_file_location,\"r\")\n",
    "        full_dictionary = text_file.read().splitlines()\n",
    "        text_file.close()\n",
    "        return full_dictionary\n",
    "                \n",
    "    def start_game(self, practice=True, verbose=True):\n",
    "        # reset guessed letters to empty set and current plausible dictionary to the full dictionary\n",
    "        self.guessed_letters = set()\n",
    "        self.current_dictionary = self.full_dictionary\n",
    "                         \n",
    "        response = self.request(\"/new_game\", {\"practice\":practice})\n",
    "        if response.get('status')==\"approved\":\n",
    "            game_id = response.get('game_id')\n",
    "            word = response.get('word')\n",
    "            tries_remains = response.get('tries_remains')\n",
    "            if verbose:\n",
    "                print(\"Successfully start a new game! Game ID: {0}. # of tries remaining: {1}. Word: {2}.\".format(game_id, tries_remains, word))\n",
    "            while tries_remains>0:\n",
    "                # get guessed letter from user code\n",
    "                guess_letter = self.guess(word)\n",
    "                    \n",
    "                # append guessed letter to guessed letters field in hangman object\n",
    "                self.guessed_letters.add(guess_letter)\n",
    "                if verbose:\n",
    "                    print(\"Guessing letter: {0}\".format(guess_letter))\n",
    "                    \n",
    "                try:    \n",
    "                    res = self.request(\"/guess_letter\", {\"request\":\"guess_letter\", \"game_id\":game_id, \"letter\":guess_letter})\n",
    "                except HangmanAPIError:\n",
    "                    print('HangmanAPIError exception caught on request.')\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print('Other exception caught on request.')\n",
    "                    raise e\n",
    "               \n",
    "                if verbose:\n",
    "                    print(\"Sever response: {0}\".format(res))\n",
    "                status = res.get('status')\n",
    "                tries_remains = res.get('tries_remains')\n",
    "                if status==\"success\":\n",
    "                    if verbose:\n",
    "                        print(\"Successfully finished game: {0}\".format(game_id))\n",
    "                    return True\n",
    "                elif status==\"failed\":\n",
    "                    reason = res.get('reason', '# of tries exceeded!')\n",
    "                    if verbose:\n",
    "                        print(\"Failed game: {0}. Because of: {1}\".format(game_id, reason))\n",
    "                    return False\n",
    "                elif status==\"ongoing\":\n",
    "                    word = res.get('word')\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Failed to start a new game\")\n",
    "        return status==\"success\"\n",
    "        \n",
    "    def my_status(self):\n",
    "        return self.request(\"/my_status\", {})\n",
    "    \n",
    "    def request(\n",
    "            self, path, args=None, post_args=None, method=None):\n",
    "        if args is None:\n",
    "            args = dict()\n",
    "        if post_args is not None:\n",
    "            method = \"POST\"\n",
    "\n",
    "        # Add `access_token` to post_args or args if it has not already been\n",
    "        # included.\n",
    "        if self.access_token:\n",
    "            # If post_args exists, we assume that args either does not exists\n",
    "            # or it does not need `access_token`.\n",
    "            if post_args and \"access_token\" not in post_args:\n",
    "                post_args[\"access_token\"] = self.access_token\n",
    "            elif \"access_token\" not in args:\n",
    "                args[\"access_token\"] = self.access_token\n",
    "\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        num_retry, time_sleep = 50, 2\n",
    "        for it in range(num_retry):\n",
    "            try:\n",
    "                response = self.session.request(\n",
    "                    method or \"GET\",\n",
    "                    self.hangman_url + path,\n",
    "                    timeout=self.timeout,\n",
    "                    params=args,\n",
    "                    data=post_args,\n",
    "                    verify=False\n",
    "                )\n",
    "                break\n",
    "            except requests.HTTPError as e:\n",
    "                response = json.loads(e.read())\n",
    "                raise HangmanAPIError(response)\n",
    "            except requests.exceptions.SSLError as e:\n",
    "                if it + 1 == num_retry:\n",
    "                    raise\n",
    "                time.sleep(time_sleep)\n",
    "\n",
    "        headers = response.headers\n",
    "        if 'json' in headers['content-type']:\n",
    "            result = response.json()\n",
    "        elif \"access_token\" in parse_qs(response.text):\n",
    "            query_str = parse_qs(response.text)\n",
    "            if \"access_token\" in query_str:\n",
    "                result = {\"access_token\": query_str[\"access_token\"][0]}\n",
    "                if \"expires\" in query_str:\n",
    "                    result[\"expires\"] = query_str[\"expires\"][0]\n",
    "            else:\n",
    "                raise HangmanAPIError(response.json())\n",
    "        else:\n",
    "            raise HangmanAPIError('Maintype was not text, or querystring')\n",
    "\n",
    "        if result and isinstance(result, dict) and result.get(\"error\"):\n",
    "            raise HangmanAPIError(result)\n",
    "        return result\n",
    "    \n",
    "class HangmanAPIError(Exception):\n",
    "    def __init__(self, result):\n",
    "        self.result = result\n",
    "        self.code = None\n",
    "        try:\n",
    "            self.type = result[\"error_code\"]\n",
    "        except (KeyError, TypeError):\n",
    "            self.type = \"\"\n",
    "\n",
    "        try:\n",
    "            self.message = result[\"error_description\"]\n",
    "        except (KeyError, TypeError):\n",
    "            try:\n",
    "                self.message = result[\"error\"][\"message\"]\n",
    "                self.code = result[\"error\"].get(\"code\")\n",
    "                if not self.type:\n",
    "                    self.type = result[\"error\"].get(\"type\", \"\")\n",
    "            except (KeyError, TypeError):\n",
    "                try:\n",
    "                    self.message = result[\"error_msg\"]\n",
    "                except (KeyError, TypeError):\n",
    "                    self.message = result\n",
    "\n",
    "        Exception.__init__(self, self.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Room for Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Tests show that the algorithm implemented above can achieve ~35% accuracy. It is better than the baseline, but not as good as I expected. Some ways to improve the algorithm are:\n",
    "\n",
    "1. Oftentimes, there are multiple alignments to match against an n-gram, some easier to solve than others. E.g., in the input word `comple_ion`, the 4-gram `?ion` is more likely to produce a correct result than `e?io`. However, in the current implementation no attempt is made to compare different alignments.\n",
    "\n",
    "2. In the same game, the `p` matrix is recalculated from scratch for each guess. Measures should be taken to calculate _incrementally_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HangmanTest(access_token=\"76e8540a498b33ed86bd8067eb0ba5\", timeout=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing  1  th game\n"
     ]
    },
    {
     "ename": "HangmanAPIError",
     "evalue": "{'error': 'Your account has been deactivated!'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHangmanAPIError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPlaying \u001b[39m\u001b[39m'\u001b[39m, i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m th game\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# Uncomment the following line to execute your final runs. Do not do this until you are satisfied with your submission\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m api\u001b[39m.\u001b[39;49mstart_game(practice\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# DO NOT REMOVE as otherwise the server may lock you out for too high frequency of requests\u001b[39;00m\n\u001b[1;32m      7\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m0.5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 131\u001b[0m, in \u001b[0;36mHangmanTest.start_game\u001b[0;34m(self, practice, verbose)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mguessed_letters \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_dictionary \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_dictionary\n\u001b[0;32m--> 131\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39m/new_game\u001b[39;49m\u001b[39m\"\u001b[39;49m, {\u001b[39m\"\u001b[39;49m\u001b[39mpractice\u001b[39;49m\u001b[39m\"\u001b[39;49m:practice})\n\u001b[1;32m    132\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapproved\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    133\u001b[0m     game_id \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mgame_id\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 233\u001b[0m, in \u001b[0;36mHangmanTest.request\u001b[0;34m(self, path, args, post_args, method)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[39mraise\u001b[39;00m HangmanAPIError(\u001b[39m'\u001b[39m\u001b[39mMaintype was not text, or querystring\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m result\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 233\u001b[0m     \u001b[39mraise\u001b[39;00m HangmanAPIError(result)\n\u001b[1;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mHangmanAPIError\u001b[0m: {'error': 'Your account has been deactivated!'}"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print('Playing ', i+1, ' th game')\n",
    "    # Uncomment the following line to execute your final runs. Do not do this until you are satisfied with your submission\n",
    "    api.start_game(practice=1, verbose=True)\n",
    "    \n",
    "    # DO NOT REMOVE as otherwise the server may lock you out for too high frequency of requests\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    [total_practice_runs,total_recorded_runs,total_recorded_successes,total_practice_successes] = api.my_status() # Get my game stats: (# of tries, # of wins)\n",
    "    practice_success_rate = total_practice_successes / (total_practice_runs + 1e-10)\n",
    "    success_rate = total_recorded_successes / (total_recorded_runs + 1e-10)\n",
    "    print(f\"- practice success rate: {practice_success_rate} (run {total_practice_runs} out of allotted 100,000).\")\n",
    "    print(f\"- recorded success rate: {success_rate} (run {total_recorded_runs} out of allotted 1000).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
